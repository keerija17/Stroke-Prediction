{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "data = pd.read_csv(\"C://Users/User/Desktop/Dissertation 2021/Stroke/testing_heart.csv\")\n",
    "data.head()\n",
    "data['bmi'].fillna(data['bmi'].mean(), inplace = True)\n",
    "# dropping unnecessary columns\n",
    "\n",
    "data.drop('ever_married', axis = 1, inplace = True)\n",
    "\n",
    "quan = data['avg_glucose_level'].quantile(0.78)\n",
    "quan2 = data['bmi'].quantile(0.98)\n",
    "print(\"Quantile limit for avg_glucose_level = \", quan)\n",
    "print(\"Quantile limit for bmi = \", quan2)\n",
    "\n",
    "filtered_data = data[data['avg_glucose_level'] < quan]\n",
    "filtered_data = filtered_data[filtered_data['bmi'] < quan2]\n",
    "filtered_data.shape\n",
    "\n",
    "# performing encoding (label encoding)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "gender = encoder.fit_transform( filtered_data['gender'] )\n",
    "smoking_status = encoder.fit_transform( filtered_data['smoking_status'] )\n",
    "work_type = encoder.fit_transform( filtered_data['work_type'] )\n",
    "Residence_type = encoder.fit_transform( filtered_data['Residence_type'] )\n",
    "filtered_data['work_type'] = work_type\n",
    "filtered_data['Residence_type'] = Residence_type\n",
    "filtered_data['smoking_status'] = smoking_status\n",
    "filtered_data['gender'] = gender\n",
    "filtered_data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4690, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = filtered_data.drop('stroke', axis = 1)\n",
    "y = filtered_data['stroke']\n",
    "# splitting the dataset for train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 2)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18759, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the train and test features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "\n",
    "x_train_std = std.fit_transform(x_train)\n",
    "x_test_std = std.transform(x_test)\n",
    "# saving scalar objects in a pickle file\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle.dump(std, open('scalar.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13464/978224260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_std\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(x_train_std.values, y_train)\n",
    "\n",
    "dt.feature_importances_\n",
    "\n",
    "x_train.columns\n",
    "\n",
    "# Clearly, age, average glucose level and bmi are the most importatnt features for decision tree classifier.\n",
    "\n",
    "y_pred_dt = dt.predict(x_test_std)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ac_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy using decison tree classification algorithm = \" +  str(ac_dt*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using logistic regression algorithm = 95.15991471215351 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train_std.values, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(x_test_std)\n",
    "\n",
    "ac_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy using logistic regression algorithm = \" +  str(ac_lr*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using k nearest neighbours algorithm = 95.01066098081023 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(x_train_std, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(x_test_std)\n",
    "\n",
    "ac_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy using k nearest neighbours algorithm = \" +  str(ac_knn*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using random forest classification algorithm = 95.13859275053305 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(x_train_std.values, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(x_test_std)\n",
    "\n",
    "ac_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy using random forest classification algorithm = \" +  str(ac_rf*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using support vector classification algorithm = 95.15991471215351 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(x_train_std.values, y_train)\n",
    "\n",
    "y_pred_svc = svc.predict(x_test_std)\n",
    "\n",
    "ac_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(\"Accuracy using support vector classification algorithm = \" +  str(ac_svc*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_svc == ac_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(lr, open(r'finalized_model.pkl', 'wb'))\n",
    "pickle.dump(rf, open(r'finalized_model_rf.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
